"""
Script ƒë·ªÉ l·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t t·ª´ vnstock (bao g·ªìm c·∫£ intraday real-time)
Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ ch·ªâ l·∫•y ƒë∆∞·ª£c data ƒë·∫øn ng√†y 14
"""

import os
import sys
from datetime import datetime, timedelta, timezone
import time
import pandas as pd
from dotenv import load_dotenv
from clickhouse_driver import Client as CHClient

load_dotenv()

# ClickHouse connection
CH_CLIENT = CHClient(
    host=os.getenv("CLICKHOUSE_HOST", "localhost"),
    port=int(os.getenv("CLICKHOUSE_PORT", "9000")),
    database=os.getenv("CLICKHOUSE_DB", "stock_db"),
    user=os.getenv("CLICKHOUSE_USER", "default"),
    password=os.getenv("CLICKHOUSE_PASSWORD", "")
)

def check_vnstock_installed():
    """Ki·ªÉm tra xem vnstock ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t ch∆∞a"""
    try:
        from vnstock import Quote
        return True
    except ImportError:
        print(" vnstock chua duoc cai dat!")
        print("\nCai dat vnstock:")
        print("  pip install vnstock")
        return False

def get_latest_data_vnstock(symbol):
    """
    L·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t t·ª´ vnstock (bao g·ªìm c·∫£ intraday)
    
    Args:
        symbol: M√£ c·ªï phi·∫øu (v√≠ d·ª•: 'VIC', 'VNM', 'VCB')
    """
    try:
        from vnstock import Quote
        
        print(f"\nDang lay du lieu moi nhat cho {symbol}...")
        
        # Kh·ªüi t·∫°o Quote object
        quote = Quote(symbol=symbol, source='VCI')
        
        # 1. Th·ª≠ l·∫•y intraday data tr∆∞·ªõc (real-time, m·ªõi nh·∫•t)
        print("  1. Thu lay intraday data (real-time)...")
        try:
            df_intraday = quote.intraday(symbol=symbol, page_size=10000, show_log=False)
            if df_intraday is not None and not df_intraday.empty:
                print(f"      Lay duoc {len(df_intraday)} records tu intraday")
                print(f"     Latest time: {df_intraday.index[-1] if isinstance(df_intraday.index, pd.DatetimeIndex) else 'N/A'}")
        except Exception as e:
            print(f"     WARNING: Khong the lay intraday: {e}")
            df_intraday = None
        
        # 2. L·∫•y historical data cho ng√†y 22-12-2025
        print("  2. Thu lay historical data cho ngay 22-12-2025...")
        start_date = '2025-12-24'
        end_date = '2025-12-24'
        try:
            df_historical = quote.history(
                start=start_date,
                end=end_date,
                interval='1m'  # D·ªØ li·ªáu theo ph√∫t trong ng√†y 22-12-2025
            )
            if df_historical is not None and not df_historical.empty:
                print(f"      Lay duoc {len(df_historical)} records tu historical")
                print(f"     Index type: {type(df_historical.index)}")
                print(f"     Columns: {list(df_historical.columns)}")
                
                # Ki·ªÉm tra xem c√≥ c·ªôt th·ªùi gian trong columns kh√¥ng
                # N·∫øu index l√† RangeIndex, t√¨m c·ªôt th·ªùi gian ƒë·ªÉ l√†m index
                time_column = None
                if isinstance(df_historical.index, pd.RangeIndex):
                    # T√¨m c·ªôt th·ªùi gian (time, date, datetime, timestamp)
                    for col in ['time', 'date', 'datetime', 'timestamp', 'Time', 'Date', 'DateTime']:
                        if col in df_historical.columns:
                            time_column = col
                            break
                    
                    if time_column:
                        print(f"     Found '{time_column}' column, using it as index...")
                        df_historical[time_column] = pd.to_datetime(df_historical[time_column], errors='coerce')
                        # Lo·∫°i b·ªè c√°c d√≤ng c√≥ time kh√¥ng h·ª£p l·ªá
                        initial_count = len(df_historical)
                        df_historical = df_historical.dropna(subset=[time_column])
                        df_historical = df_historical.set_index(time_column)
                        print(f"      Set '{time_column}' column as index, {len(df_historical)} valid records")
                    else:
                        print(f"     WARNING: Warning: RangeIndex but no time column found in: {list(df_historical.columns)}")
                elif not isinstance(df_historical.index, pd.DatetimeIndex):
                    print(f"     Converting index to DatetimeIndex...")
                    df_historical.index = pd.to_datetime(df_historical.index, errors='coerce')
                    # Lo·∫°i b·ªè c√°c d√≤ng c√≥ timestamp kh√¥ng h·ª£p l·ªá
                    initial_count = len(df_historical)
                    df_historical = df_historical.dropna(subset=[df_historical.columns[0]])
                    if len(df_historical) < initial_count:
                        print(f"     WARNING: Removed {initial_count - len(df_historical)} records with invalid timestamps")
                
                # Filter ra c√°c records c√≥ nƒÉm 1970 (epoch 0) ho·∫∑c nƒÉm < 2000
                if isinstance(df_historical.index, pd.DatetimeIndex):
                    initial_count = len(df_historical)
                    df_historical = df_historical[df_historical.index.year >= 2000]
                    if len(df_historical) < initial_count:
                        print(f"     WARNING: Removed {initial_count - len(df_historical)} records with year < 2000")
                    print(f"     Time range: {df_historical.index[0]} to {df_historical.index[-1]}")
                else:
                    print(f"     WARNING: Warning: Index is still not DatetimeIndex after conversion")
                    print(f"     First index value: {df_historical.index[0]}")
                    print(f"     Last index value: {df_historical.index[-1]}")
        except Exception as e:
            print(f"     WARNING: Khong the lay historical: {e}")
            df_historical = None
        
        # 3. K·∫øt h·ª£p d·ªØ li·ªáu (∆∞u ti√™n historical ng√†y 22-12-2025, sau ƒë√≥ b·ªï sung intraday n·∫øu c√≥)
        if df_historical is not None and not df_historical.empty:
            df = df_historical
            print(f"   Su dung historical data ngay 22-12-2025 ({len(df)} records)")
            
            # N·∫øu c√≥ intraday data, k·∫øt h·ª£p v√†o (b·ªï sung d·ªØ li·ªáu m·ªõi nh·∫•t)
            if df_intraday is not None and not df_intraday.empty:
                print(f"   Bo sung intraday data ({len(df_intraday)} records)...")
                # C√≥ th·ªÉ append intraday v√†o historical n·∫øu c·∫ßn
                # T·∫°m th·ªùi ch·ªâ d√πng historical ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ ƒë·ªß 1825 ng√†y
        elif df_intraday is not None and not df_intraday.empty:
            df = df_intraday
            print(f"  WARNING: Chi co intraday data ({len(df)} records), khong co historical")
        else:
            print(f"   Khong co du lieu nao")
            return None
        
        return df
        
    except Exception as e:
        print(f"   Loi khi lay du lieu: {e}")
        import traceback
        traceback.print_exc()
        return None

def calculate_total_gross_trade_amount(high, low, close, volume):
    """
    T√≠nh total_gross_trade_amount theo c√¥ng th·ª©c:
    Typical Price = (high + low + close) / 3
    total_gross_trade_amount = Typical Price √ó volume
    """
    typical_price = (high + low + close) / 3.0
    return typical_price * volume

def insert_vnstock_data_to_clickhouse(df, symbol):
    """
    Insert d·ªØ li·ªáu t·ª´ vnstock DataFrame v√†o ClickHouse b·∫£ng ohlc
    
    Args:
        df: DataFrame t·ª´ vnstock
        symbol: M√£ c·ªï phi·∫øu
    """
    if df is None or df.empty:
        return False
    
    try:
        print(f"\nDang insert {len(df)} records vao ClickHouse...")
        
        inserted = 0
        skipped = 0
        batch_data = []  # Batch insert ƒë·ªÉ tƒÉng performance
        
        # Ki·ªÉm tra xem l√† intraday data hay historical data
        # Intraday c√≥ columns: ['time', 'price', 'volume', 'match_type', 'id']
        # Historical c√≥ columns: ['open', 'high', 'low', 'close', 'volume'] v·ªõi index l√† time
        is_intraday = 'price' in df.columns and 'time' in df.columns
        
        if is_intraday:
            print(f"   Detected: Intraday data format")
            print(f"     Columns: {list(df.columns)}")
            print(f"     Will aggregate by minute to get OHLC...")
            
            # Aggregate intraday data theo ph√∫t ƒë·ªÉ c√≥ OHLC
            # Chuy·ªÉn time column th√†nh datetime n·∫øu ch∆∞a
            if 'time' in df.columns:
                df['time'] = pd.to_datetime(df['time'], errors='coerce')
                # Lo·∫°i b·ªè c√°c d√≤ng c√≥ time kh√¥ng h·ª£p l·ªá
                df = df.dropna(subset=['time'])
                df = df.set_index('time')
                # ƒê·∫£m b·∫£o index l√† DatetimeIndex
                if not isinstance(df.index, pd.DatetimeIndex):
                    df.index = pd.to_datetime(df.index, errors='coerce')
                    df = df.dropna(subset=[df.columns[0]])
            
            # Aggregate theo ph√∫t
            df_agg = df.groupby(pd.Grouper(freq='1min')).agg({
                'price': ['first', 'max', 'min', 'last'],  # open, high, low, close
                'volume': 'sum'
            })
            
            # Flatten column names
            df_agg.columns = ['open', 'high', 'low', 'close', 'volume']
            df_agg = df_agg.dropna()  # B·ªè c√°c ph√∫t kh√¥ng c√≥ data
            
            print(f"     Aggregated to {len(df_agg)} records (1-minute bars)")
            df = df_agg
        else:
            print(f"   Detected: Historical data format")
            print(f"     Columns: {list(df.columns)}")
            print(f"     Index type: {type(df.index)}")
            
            # ƒê·∫£m b·∫£o index l√† DatetimeIndex
            if not isinstance(df.index, pd.DatetimeIndex):
                print(f"     Converting index to DatetimeIndex...")
                try:
                    df.index = pd.to_datetime(df.index, errors='coerce')
                    # Lo·∫°i b·ªè c√°c d√≤ng c√≥ timestamp kh√¥ng h·ª£p l·ªá (NaT)
                    initial_count = len(df)
                    df = df.dropna(subset=[df.columns[0]])  # Drop rows v·ªõi NaT index
                    nat_removed = initial_count - len(df)
                    if nat_removed > 0:
                        print(f"     WARNING: Removed {nat_removed} records with NaT timestamps")
                    
                    # Filter ra c√°c records c√≥ nƒÉm 1970 (epoch 0)
                    if isinstance(df.index, pd.DatetimeIndex):
                        before_epoch_filter = len(df)
                        df = df[df.index.year >= 2000]
                        epoch_removed = before_epoch_filter - len(df)
                        if epoch_removed > 0:
                            print(f"     WARNING: Removed {epoch_removed} records with year < 2000")
                    
                    print(f"      Converted to DatetimeIndex, {len(df)} valid records remaining")
                except Exception as e:
                    print(f"     WARNING: Error converting index: {e}")
            else:
                # Index ƒë√£ l√† DatetimeIndex, nh∆∞ng v·∫´n c·∫ßn filter nƒÉm 1970
                initial_count = len(df)
                df = df[df.index.year >= 2000]
                if len(df) < initial_count:
                    print(f"     WARNING: Removed {initial_count - len(df)} records with year < 2000")
        
        # ƒê·∫£m b·∫£o index l√† DatetimeIndex tr∆∞·ªõc khi x·ª≠ l√Ω
        if not isinstance(df.index, pd.DatetimeIndex):
            print(f"  WARNING: Warning: Index is not DatetimeIndex, attempting conversion...")
            print(f"     Index type: {type(df.index)}")
            print(f"     Sample index values: {df.index[:3].tolist() if len(df) > 0 else 'N/A'}")
            df.index = pd.to_datetime(df.index, errors='coerce')
            # ƒê·∫øm s·ªë NaT (Not a Time) sau khi convert
            nat_count = df.index.isna().sum()
            if nat_count > 0:
                print(f"     WARNING: Found {nat_count} invalid timestamps (NaT), removing...")
            df = df.dropna(subset=[df.columns[0]])
            print(f"      After conversion: {len(df)} valid records")
        
        # Filter ra c√°c records c√≥ timestamp kh√¥ng h·ª£p l·ªá (nƒÉm 1970 = epoch 0)
        if isinstance(df.index, pd.DatetimeIndex):
            initial_count = len(df)
            # Lo·∫°i b·ªè c√°c records c√≥ nƒÉm < 2000 (bao g·ªìm nƒÉm 1970)
            df = df[df.index.year >= 2000]
            removed_count = initial_count - len(df)
            if removed_count > 0:
                print(f"   Removed {removed_count} records with invalid timestamps (year < 2000)")
                print(f"     Remaining: {len(df)} valid records")
            
            # Ki·ªÉm tra xem c√≥ c·ªôt 'time' trong columns kh√¥ng (c√≥ th·ªÉ conflict v·ªõi index)
            if 'time' in df.columns:
                print(f"  WARNING: Warning: Found 'time' column in data, removing to avoid conflict with index")
                df = df.drop(columns=['time'])
        
        # B√¢y gi·ªù df ƒë√£ c√≥ format chu·∫©n: index l√† time, columns l√† open, high, low, close, volume
        for idx, row in df.iterrows():
            try:
                # Parse timestamp t·ª´ index (ƒë√£ ƒë·∫£m b·∫£o l√† DatetimeIndex)
                timestamp = idx
                
                # Ki·ªÉm tra n·∫øu l√† NaT (Not a Time)
                if pd.isna(timestamp):
                    skipped += 1
                    continue
                
                # Convert sang datetime object
                if isinstance(timestamp, pd.Timestamp):
                    timestamp = timestamp.to_pydatetime()
                elif hasattr(timestamp, 'to_pydatetime'):
                    timestamp = timestamp.to_pydatetime()
                elif isinstance(timestamp, datetime):
                    pass  # ƒê√£ l√† datetime
                elif isinstance(timestamp, (int, float)):
                    # N·∫øu l√† s·ªë, c√≥ th·ªÉ l√† Unix timestamp
                    # Ki·ªÉm tra s·ªë ch·ªØ s·ªë ƒë·ªÉ x√°c ƒë·ªãnh milliseconds hay seconds
                    if timestamp > 1e12:  # Milliseconds (13+ digits)
                        timestamp = datetime.fromtimestamp(timestamp / 1000)
                    elif timestamp > 1e9:  # Seconds (10 digits)
                        timestamp = datetime.fromtimestamp(timestamp)
                    else:
                        # S·ªë qu√° nh·ªè, c√≥ th·ªÉ l√† l·ªói
                        print(f"  WARNING: Invalid timestamp value: {timestamp}, using current time")
                        timestamp = datetime.now()
                elif isinstance(timestamp, str):
                    try:
                        timestamp = pd.to_datetime(timestamp).to_pydatetime()
                    except:
                        try:
                            timestamp = datetime.strptime(timestamp, "%Y-%m-%d %H:%M:%S")
                        except:
                            try:
                                timestamp = datetime.strptime(timestamp, "%Y-%m-%d")
                            except:
                                print(f"  WARNING: Cannot parse timestamp string: {timestamp}, using current time")
                                timestamp = datetime.now()
                else:
                    # Th·ª≠ convert b·∫±ng pandas
                    try:
                        timestamp = pd.to_datetime(timestamp).to_pydatetime()
                    except:
                        print(f"  WARNING: Cannot convert timestamp: {type(timestamp)} = {timestamp}, using current time")
                        timestamp = datetime.now()
                
                # Validate timestamp (ƒë√£ filter tr∆∞·ªõc nh∆∞ng v·∫´n ki·ªÉm tra ƒë·ªÉ an to√†n)
                if timestamp.year < 2000:
                    # Kh√¥ng n√™n x·∫£y ra v√¨ ƒë√£ filter tr∆∞·ªõc, nh∆∞ng v·∫´n ki·ªÉm tra
                    skipped += 1
                    continue
                
                # Debug: In m·ªôt v√†i timestamp ƒë·∫ßu ti√™n ƒë·ªÉ ki·ªÉm tra
                if inserted == 0 and skipped == 0:
                    print(f"  üìÖ Sample timestamp: {timestamp} (type: {type(timestamp)})")
                    print(f"  üìÖ Sample data: open={row.get('open', 'N/A')}, close={row.get('close', 'N/A')}")
                
                # L·∫•y gi√° tr·ªã OHLCV
                open_val = float(row.get('open', row.get('Open', 0)))
                high_val = float(row.get('high', row.get('High', 0)))
                low_val = float(row.get('low', row.get('Low', 0)))
                close_val = float(row.get('close', row.get('Close', 0)))
                volume_val = int(float(row.get('volume', row.get('Volume', 0))))
                
                # Ki·ªÉm tra gi√° tr·ªã h·ª£p l·ªá
                if open_val == 0 and high_val == 0 and low_val == 0 and close_val == 0:
                    skipped += 1
                    continue
                
                # T√≠nh total_gross_trade_amount theo c√¥ng th·ª©c:
                # Typical Price = (high + low + close) / 3
                # total_gross_trade_amount = Typical Price √ó volume
                total_gross_trade_amount = calculate_total_gross_trade_amount(
                    high_val, low_val, close_val, volume_val
                )
                
                # Convert timestamp sang UTC+7 (gi·ªù Vi·ªát Nam) - naive datetime
                # ClickHouse l∆∞u datetime UTC+7 (naive)
                vn_timezone = timezone(timedelta(hours=7))
                if timestamp.tzinfo is None:
                    # N·∫øu l√† naive datetime, gi·∫£ s·ª≠ ƒë√£ l√† UTC+7
                    timestamp_vn = timestamp
                else:
                    # Convert t·ª´ UTC sang UTC+7
                    timestamp_utc = timestamp.astimezone(timezone.utc)
                    timestamp_vn = timestamp_utc.astimezone(vn_timezone).replace(tzinfo=None)
                
                # Th√™m v√†o batch
                batch_data.append((
                    symbol,
                    timestamp_vn,  # DateTime (UTC+7, naive)
                    '1m',  # interval
                    open_val,
                    high_val,
                    low_val,
                    close_val,
                    volume_val,
                    0,  # trade_count (kh√¥ng c√≥ t·ª´ vnstock)
                    total_gross_trade_amount
                ))
                
                inserted += 1
                
                # Batch insert m·ªói 1000 records
                if len(batch_data) >= 1000:
                    insert_batch_to_clickhouse(batch_data)
                    batch_data = []
                
            except Exception as e:
                skipped += 1
                if inserted == 0 and skipped <= 3:  # In l·ªói ƒë·∫ßu ti√™n ƒë·ªÉ debug
                    print(f"  WARNING: Error inserting row: {e}")
                    print(f"     Index: {idx}, Row: {dict(row) if hasattr(row, 'to_dict') else 'N/A'}")
                continue
        
        # Insert batch cu·ªëi c√πng n·∫øu c√≤n
        if batch_data:
            insert_batch_to_clickhouse(batch_data)
        
        print(f"\n Inserted: {inserted} records")
        print(f"WARNING: Skipped: {skipped} records")
        
        return inserted > 0
        
    except Exception as e:
        print(f"\n Loi khi insert vao ClickHouse: {e}")
        import traceback
        traceback.print_exc()
        return False

def check_table_schema(table_name):
    """
    Ki·ªÉm tra schema c·ªßa b·∫£ng trong ClickHouse
    
    Returns:
        dict v·ªõi keys: 'columns', 'engine', 'has_trade_count'
    """
    try:
        # L·∫•y th√¥ng tin v·ªÅ b·∫£ng
        result = CH_CLIENT.execute(f"DESCRIBE TABLE stock_db.{table_name}")
        columns = {row[0]: row[1] for row in result}  # column_name: column_type
        
        # Ki·ªÉm tra engine
        engine_result = CH_CLIENT.execute(f"SELECT engine FROM system.tables WHERE database = 'stock_db' AND name = '{table_name}'")
        engine = engine_result[0][0] if engine_result else 'Unknown'
        
        return {
            'columns': columns,
            'engine': engine,
            'has_trade_count': 'trade_count' in columns
        }
    except Exception as e:
        print(f"  WARNING: Cannot check schema for {table_name}: {e}")
        return None

def create_temp_table_if_not_exists():
    """
    T·∫°o b·∫£ng t·∫°m ƒë·ªÉ insert OHLC data t·ª´ vnstock
    B·∫£ng n√†y d√πng MergeTree (kh√¥ng ph·∫£i AggregatingMergeTree) ƒë·ªÉ c√≥ th·ªÉ insert tr·ª±c ti·∫øp
    """
    try:
        # Ki·ªÉm tra xem b·∫£ng ƒë√£ t·ªìn t·∫°i ch∆∞a
        result = CH_CLIENT.execute(
            "SELECT name FROM system.tables WHERE database = 'stock_db' AND name = 'ohlc_vnstock_temp'"
        )
        if result:
            return  # B·∫£ng ƒë√£ t·ªìn t·∫°i
        
        # T·∫°o b·∫£ng t·∫°m
        create_table_query = """
        CREATE TABLE IF NOT EXISTS stock_db.ohlc_vnstock_temp
        (
            symbol String,
            time DateTime64(3),
            interval String,
            open Float64,
            high Float64,
            low Float64,
            close Float64,
            volume UInt64,
            total_gross_trade_amount Float64
        )
        ENGINE = MergeTree()
        PARTITION BY toYYYYMM(time)
        ORDER BY (symbol, interval, time)
        SETTINGS index_granularity = 8192
        """
        CH_CLIENT.execute(create_table_query)
        print(f"   Created temporary table: ohlc_vnstock_temp")
    except Exception as e:
        print(f"  WARNING: Error creating temp table: {e}")
        raise

def insert_batch_to_clickhouse(batch_data):
    """
    Insert batch data v√†o ClickHouse
    V√¨ b·∫£ng ohlc l√† AggregatingMergeTree, kh√¥ng th·ªÉ insert state functions tr·ª±c ti·∫øp
    Gi·∫£i ph√°p: Insert v√†o b·∫£ng t·∫°m (MergeTree) tr∆∞·ªõc, sau ƒë√≥ d√πng INSERT SELECT ƒë·ªÉ chuy·ªÉn v√†o ohlc
    """
    if not batch_data:
        return
    
    try:
        # T·∫°o b·∫£ng t·∫°m n·∫øu ch∆∞a c√≥
        create_temp_table_if_not_exists()
        
        # Ki·ªÉm tra schema c·ªßa b·∫£ng ohlc
        ohlc_schema = check_table_schema('ohlc')
        if not ohlc_schema:
            raise Exception("Cannot find ohlc table")
        
        use_trade_count = ohlc_schema.get('has_trade_count', False)
        is_aggregating = 'AggregatingMergeTree' in str(ohlc_schema.get('engine', ''))
        
        print(f"   Target table: ohlc (engine: {ohlc_schema.get('engine')}, has trade_count: {use_trade_count})")
        
        # Insert v√†o b·∫£ng t·∫°m tr∆∞·ªõc (MergeTree - c√≥ th·ªÉ insert gi√° tr·ªã tr·ª±c ti·∫øp)
        values_list = []
        for row in batch_data:
            symbol, time, interval, open_val, high_val, low_val, close_val, volume_val, trade_count, total_gross_trade_amount = row
            # Format time cho SQL (DateTime)
            if isinstance(time, datetime):
                time_str = time.strftime('%Y-%m-%d %H:%M:%S')
            else:
                time_str = str(time)
            
            # Escape single quotes trong symbol
            symbol_escaped = symbol.replace("'", "''")
            
            # Insert gi√° tr·ªã tr·ª±c ti·∫øp v√†o b·∫£ng t·∫°m (kh√¥ng d√πng state functions)
            values_list.append(
                f"('{symbol_escaped}', '{time_str}', '{interval}', "
                f"{open_val}, {high_val}, {low_val}, {close_val}, "
                f"{volume_val}, {total_gross_trade_amount})"
            )
        
        values_sql = ", ".join(values_list)
        
        # Insert v√†o b·∫£ng t·∫°m
        insert_temp_query = f"""
            INSERT INTO stock_db.ohlc_vnstock_temp 
            (symbol, time, interval, open, high, low, close, volume, total_gross_trade_amount)
            VALUES {values_sql}
        """
        CH_CLIENT.execute(insert_temp_query)
        
        # N·∫øu ohlc l√† AggregatingMergeTree, c·∫ßn chuy·ªÉn t·ª´ temp table sang ohlc b·∫±ng INSERT SELECT
        if is_aggregating:
            # Chuy·ªÉn t·ª´ temp table sang ohlc v·ªõi state functions
            if use_trade_count:
                transfer_query = """
                    INSERT INTO stock_db.ohlc 
                    (symbol, time, interval, open, high, low, close, volume, trade_count, total_gross_trade_amount)
                    SELECT
                        symbol,
                        time,
                        interval,
                        argMinState(open, toDateTime64(time, 3)) AS open,
                        maxState(high) AS high,
                        minState(low) AS low,
                        argMaxState(close, toDateTime64(time, 3)) AS close,
                        sumState(volume) AS volume,
                        countState() AS trade_count,
                        sumState(total_gross_trade_amount) AS total_gross_trade_amount
                    FROM stock_db.ohlc_vnstock_temp
                    GROUP BY symbol, time, interval
                """
            else:
                transfer_query = """
                    INSERT INTO stock_db.ohlc 
                    (symbol, time, interval, open, high, low, close, volume, total_gross_trade_amount)
                    SELECT
                        symbol,
                        time,
                        interval,
                        argMinState(open, time) AS open,
                        maxState(high) AS high,
                        minState(low) AS low,
                        argMaxState(close, time) AS close,
                        sumState(volume) AS volume,
                        sumState(total_gross_trade_amount) AS total_gross_trade_amount
                    FROM stock_db.ohlc_vnstock_temp
                    GROUP BY symbol, time, interval
                """
            
            CH_CLIENT.execute(transfer_query)
            
            # X√≥a d·ªØ li·ªáu ƒë√£ chuy·ªÉn t·ª´ temp table (optional, ƒë·ªÉ ti·∫øt ki·ªám dung l∆∞·ª£ng)
            # CH_CLIENT.execute("TRUNCATE TABLE stock_db.ohlc_vnstock_temp")
        else:
            # N·∫øu ohlc kh√¥ng ph·∫£i AggregatingMergeTree, copy tr·ª±c ti·∫øp
            if use_trade_count:
                transfer_query = """
                    INSERT INTO stock_db.ohlc 
                    (symbol, time, interval, open, high, low, close, volume, trade_count, total_gross_trade_amount)
                    SELECT
                        symbol,
                        time,
                        interval,
                        open,
                        high,
                        low,
                        close,
                        volume,
                        1 AS trade_count,  -- M·∫∑c ƒë·ªãnh 1 v√¨ kh√¥ng c√≥ th√¥ng tin t·ª´ vnstock
                        total_gross_trade_amount
                    FROM stock_db.ohlc_vnstock_temp
                """
            else:
                transfer_query = """
                    INSERT INTO stock_db.ohlc 
                    (symbol, time, interval, open, high, low, close, volume, total_gross_trade_amount)
                    SELECT
                        symbol,
                        time,
                        interval,
                        open,
                        high,
                        low,
                        close,
                        volume,
                        total_gross_trade_amount
                    FROM stock_db.ohlc_vnstock_temp
                """
            
            CH_CLIENT.execute(transfer_query)
            CH_CLIENT.execute("TRUNCATE TABLE stock_db.ohlc_vnstock_temp")
            print("  üßπ B·∫£ng t·∫°m ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch cho batch ti·∫øp theo.")
    except Exception as e:
        print(f"   Error inserting batch: {e}")
        import traceback
        traceback.print_exc()
        raise


def get_symbols_from_file(file_path='symbol.txt'):
    """
    L·∫•y danh s√°ch symbols t·ª´ file text (m·ªói d√≤ng m·ªôt symbol)
    
    Args:
        file_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file ch·ª©a symbols
    
    Returns:
        List of symbols (ƒë√£ lo·∫°i b·ªè tr√πng l·∫∑p v√† d√≤ng tr·ªëng)
    """
    try:
        if not os.path.exists(file_path):
            print(f"WARNING: File {file_path} kh√¥ng t·ªìn t·∫°i!")
            return []
        
        symbols = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng v√† k√Ω t·ª± xu·ªëng d√≤ng
                symbol = line.strip().upper()
                # B·ªè qua d√≤ng tr·ªëng
                if symbol:
                    symbols.append(symbol)
        
        # Lo·∫°i b·ªè tr√πng l·∫∑p nh∆∞ng gi·ªØ nguy√™n th·ª© t·ª±
        seen = set()
        unique_symbols = []
        for symbol in symbols:
            if symbol not in seen:
                seen.add(symbol)
                unique_symbols.append(symbol)
        
        if len(symbols) != len(unique_symbols):
            print(f"  WARNING: ƒê√£ lo·∫°i b·ªè {len(symbols) - len(unique_symbols)} symbols tr√πng l·∫∑p")
        
        return unique_symbols
    except Exception as e:
        print(f" Error reading symbols from file {file_path}: {e}")
        return []

def main():
    print("="*70)
    print("DOWNLOAD DATA NGAY 22-12-2025 TU VNSTOCK")
    print("="*70)

    # Ki·ªÉm tra vnstock
    if not check_vnstock_installed():
        sys.exit(1)

    #  CH·ªà L·∫§Y SYMBOL T·ª™ FILE symbol.txt
    print(f"\n ƒê·ªçc symbols t·ª´ file symbol.txt...")
    symbols = get_symbols_from_file('symbol.txt')

    print(f" ƒê·ªçc ƒë∆∞·ª£c {len(symbols)} symbols")
    print(f"   Sample: {', '.join(symbols[:10])}")
    if len(symbols) > 10:
        print(f"   ... v√† {len(symbols) - 10} symbols kh√°c")

    print("\n" + "="*70)

    success_count = 0
    failed_symbols = []
    no_data_symbols = []

    total_symbols = len(symbols)
    start_time = time.time()

    print(f"\n B·∫Øt ƒë·∫ßu x·ª≠ l√Ω {total_symbols} symbols...")
    print(f" C√≥ th·ªÉ d·ª´ng b·∫±ng Ctrl+C\n")

    # X·ª≠ l√Ω t·ª´ng symbol
    for idx, symbol in enumerate(symbols, 1):
        try:
            print(f"\n{'='*70}")
            print(f"[{idx}/{total_symbols}] X·ª≠ l√Ω {symbol}")
            print(f"{'='*70}")
            
            # L·∫•y d·ªØ li·ªáu t·ª´ vnstock
            df = get_latest_data_vnstock(symbol)
            
            if df is None or df.empty:
                print(f"  WARNING: Kh√¥ng c√≥ d·ªØ li·ªáu cho {symbol}")
                no_data_symbols.append(symbol)
                continue
            
            # Insert v√†o ClickHouse
            success = insert_vnstock_data_to_clickhouse(df, symbol)
            
            if success:
                success_count += 1
                print(f"   Th√†nh c√¥ng: {symbol}")
            else:
                failed_symbols.append(symbol)
                print(f"   Th·∫•t b·∫°i: {symbol}")
            
            # Ngh·ªâ m·ªôt ch√∫t ƒë·ªÉ tr√°nh rate limit
            if idx < total_symbols:
                time.sleep(1)
                
        except KeyboardInterrupt:
            print(f"\n\nWARNING: ƒê√£ d·ª´ng b·ªüi ng∆∞·ªùi d√πng (Ctrl+C)")
            print(f"   ƒê√£ x·ª≠ l√Ω: {idx-1}/{total_symbols} symbols")
            break
        except Exception as e:
            print(f"\n   L·ªói khi x·ª≠ l√Ω {symbol}: {e}")
            failed_symbols.append(symbol)
            import traceback
            traceback.print_exc()
            continue
    
    # T√≥m t·∫Øt k·∫øt qu·∫£
    elapsed_time = time.time() - start_time
    print(f"\n{'='*70}")
    print("K·∫æT QU·∫¢")
    print(f"{'='*70}")
    print(f" Th√†nh c√¥ng: {success_count}/{total_symbols}")
    print(f" Th·∫•t b·∫°i: {len(failed_symbols)}")
    print(f"WARNING: Kh√¥ng c√≥ d·ªØ li·ªáu: {len(no_data_symbols)}")
    print(f" Th·ªùi gian: {elapsed_time:.2f} gi√¢y")
    
    if failed_symbols:
        print(f"\n Symbols th·∫•t b·∫°i: {', '.join(failed_symbols)}")
    if no_data_symbols:
        print(f"\nWARNING: Symbols kh√¥ng c√≥ d·ªØ li·ªáu: {', '.join(no_data_symbols)}")
    
    print(f"\n{'='*70}")

if __name__ == "__main__":
    main()

